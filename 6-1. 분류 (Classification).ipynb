{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6장. 분류 (Classification)\n",
    "\n",
    "- Regression이 결과값을 추정하는 방식이었다면, Classification은 카테고리에 분류하는 방식\n",
    "- Linear regression은 Classification에 사용할 수 없으므로 Logistic Regression 사용\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀(Logistic Regression)\n",
    "\n",
    "- 0~1 사이의 값만 내보내는 함수가 필요하다.\n",
    "- 0 <= h(x) <= 1\n",
    "- Sigmoid (logistic) function\n",
    "\n",
    "<img src=\"./img/log.png\" width=\"400\" height=\"400\"></img>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱 함수 도출\n",
    "\n",
    "ref) https://mazdah.tistory.com/769\n",
    "\n",
    "1. Classification은 0 또는 1 값만 가지는데, linear regression은 그 범위 이상의 값을 가질 수 있다.\n",
    "\n",
    "\n",
    "2. 두 개의 결과만을 도출하는 과정을 여러번 시행하면 확률이 되며 확률 또한 범위는 0부터 1까지로 제한된다.<br>\n",
    "(예를 들어, 하루에 담배 10개피를 피운 사람 a를 조사했더니 폐암에 걸렸다(1). 그런데 하루에 담배 10개피를 피운 사람을 10명 조사했더니 6명은 폐암에 걸렸으나 4명은 걸리지 않았다. 결국 10개피의 담배를 피운 사람은 60%의 확률로 폐암에 걸렸다고 말할 수 있는 것이다.)\n",
    "\n",
    "\n",
    "3. 0부터 1까지로 값이 제한된 확률 값의 범위를 0부터 ∞로 확장하기 위해 odds 비(실패 확률에 대한 성공 확률의 비율)를 취한다.\n",
    "<img src=\"./img/Odds.png\" width=\"200\" height=\"200\"></img>\n",
    "\n",
    "    (P는 0~1 사이의 값을 가지므로 0인 경우 0/1-0 = 0이 되고, 가장 큰 1이 되는 경우 1/1-1 = 1/0이 되어 무한대가 된다.)\n",
    "    \n",
    "\n",
    "4. 0부터 ∞까지로 확장된 결과를 다시 -∞에서 ∞로 확장하기 위해 odds 비의 식에 자연로그를 취한다(이 과정을 logit 변환이라고도 한다).\n",
    "\n",
    "<img src=\"./img/log2.png\" width=\"200\" height=\"200\"></img>\n",
    "\n",
    "\n",
    "5. 이제 양쪽의 식이 모두 -∞에서 ∞까지의 값을 갖게 되므로 등식이 성립하고 이 등식을 변형하면 우리가 원하는 로지스틱 함수가 도출된다.\n",
    "\n",
    "<img src=\"./img/log3.png\" width=\"200\" height=\"200\"></img>\n",
    "<img src=\"./img/log4.png\" width=\"400\" height=\"400\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Boundary\n",
    "\n",
    "ref) http://gnujoow.github.io/ml/2016/01/29/ML3-Logistic-Regression/\n",
    "\n",
    "<img src=\"./img/log5.png\" width=\"400\" height=\"400\"></img>\n",
    "<img src=\"./img/log6.png\" width=\"200\" height=\"200\"></img>\n",
    "<img src=\"./img/log7.png\" width=\"400\" height=\"400\"></img>\n",
    "<img src=\"./img/log8.png\" width=\"200\" height=\"200\"></img>\n",
    "결론적으로\n",
    "<img src=\"./img/log9.png\" width=\"200\" height=\"200\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "\n",
    "ref) http://gnujoow.github.io/ml/2016/01/29/ML3-Logistic-Regression/\n",
    "\n",
    "- 𝜃 parameter 값을 어떻게 정할까? • \n",
    "- Linear regression을 그대로 사용하면 non-convex \n",
    "- **Logistic 만의 cost function이 필요하다**\n",
    "\n",
    "<img src=\"./img/log10.png\" width=\"700\" height=\"700\"></img>\n",
    "\n",
    "<img src=\"./img/log11.png\" width=\"700\" height=\"700\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "\n",
    "<img src=\"./img/log12.png\" width=\"700\" height=\"700\"></img>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
